!pip install tensorflow-gpu
import tensorflow as tf

print(tf.__version__)

import numpy as np
import pandas as pd
import seaborn as sns

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import LinearSVC

import matplotlib.pyplot as plt

lr = LogisticRegression()
svc= LinearSVC(C=1.0)
rfc =RandomForestClassifier(n_estimators=100)

from google.colab import files
uploaded = files.upload()

df= pd.read_csv('diabetes.csv')

df.head(15)
df.isnull().values.any()

df.info()

import sklearn
from sklearn.neural_network import MLPClassifier

import seaborn as sns
import matplotlib.pyplot as plt
corrmat = df.corr()
top_corr_features = corrmat.index
plt.figure(figsize=(20,20))
g=sns.heatmap(df[top_corr_features].corr(),annot=True,cmap="RdYlGn")

df.corr()

#model starts from here
from sklearn.model_selection import train_test_split
features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'BMI', 'DiabetesPedigreeFunction', 'Age']
prediction = ['Outcome']

X = df[features].values
Y= df[prediction].values

X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.30, random_state=10)

random_forest_model = RandomForestClassifier(random_state=10)
random_forest_model.fit(X_train, Y_train.ravel())

predict_train_data = random_forest_model.predict(X_test)
from sklearn import metrics
print("Accuracy = {0:.3f}".format(metrics.accuracy_score(Y_test, predict_train_data)))

def create_feature_column():
    
    feat_Pregnancies = tf.feature_column.numeric_column('Pregnancies')
    feat_Glucose = tf.feature_column.numeric_column('Glucose')
    feat_BloodPressure = tf.feature_column.numeric_column('BloodPressure')
    feat_SkinThickness_tricep = tf.feature_column.numeric_column('SkinThickness')
    feat_Insulin = tf.feature_column.numeric_column('Insulin')
    feat_BMI = tf.feature_column.numeric_column('BMI')
    feat_DiabetesPedigreeFunction  = tf.feature_column.numeric_column('DiabetesPedigreeFunction')
    feat_Age = tf.feature_column.numeric_column('Age')
    feature_column = [feat_Pregnancies, feat_Glucose, feat_BloodPressure, 
                  feat_SkinThickness_tricep, feat_Insulin, 
                 feat_BMI , feat_DiabetesPedigreeFunction, feat_Age] 
    
    return feature_column


#Testing Model
import xgboost
classifier=xgboost.XGBClassifier()

classifier=xgboost.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=0.3, gamma=0.0, learning_rate=0.25,
       max_delta_step=0, max_depth=3, min_child_weight=7, missing=None,
       n_estimators=100, n_jobs=1, nthread=None,
       objective='binary:logistic', random_state=0, reg_alpha=0,
       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,
       subsample=1)
       
from sklearn.model_selection import cross_val_score
score=cross_val_score(classifier,X,Y.ravel(),cv=10)

score

#Final Predicted Score
score.mean()



































